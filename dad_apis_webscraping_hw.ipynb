{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josepeon/python_dad_class/blob/main/dad_apis_webscraping_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homework III: API's and Webscraping"
      ],
      "metadata": {
        "id": "KepG7PStNviu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_M6btA_INoE8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1\n",
        "\n",
        "Using the LastFM API, look up your five favorite artists (using [here](https://www.last.fm/api/show/artist.getTopAlbums)) top albums and create a DataFrame of your results formatted as shown below:\n",
        "\n",
        "| Artist | Album | Album Art Link |\n",
        "| ------ | ------ | ------------  |\n",
        "| Riff Raff | Pink Panther | www.lastfm.com/panther |\n",
        "| Slayer | South of Heaven | www.lastfm.com/slay |"
      ],
      "metadata": {
        "id": "aRWHCR0YN9YA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1f55h2zWOzi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ENpOz4EBOzZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CHeDwkZ2Oymu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2\n",
        "\n",
        "Using the LastFM API, look up tracks similar (using [this](https://www.last.fm/api/show/track.getSimilar)) to Quicksand's song Fazer.  Assemble the results in a DataFrame with the format given below:\n",
        "\n",
        "| Artist | Song | Playcount | Match % | Duration |\n",
        "| ------ | ------- | ------ | ------ | ---------- |\n",
        "| quicksand | can opener | 98218 | 1.0 | 219 |"
      ],
      "metadata": {
        "id": "ArqnDnxFO0tf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hofj3ZuHRxeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mpKESWK3RxN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kW98BBbeRaAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 3\n",
        "\n",
        "arXiv is an open source space for academic papers to be published.  They have a freely accessible API [here](https://info.arxiv.org/help/api/user-manual.html#arxiv-api-users-manual).  In order to parse the responses, you will need to use the BeautifulSoup library and turn the text of the response into a soup object that is then searched.\n",
        "\n",
        "Your objective is to write a function that takes in a search term and returns a `DataFrame` with the article date, title, authors, summary, and article url as columns of the `DataFrame`."
      ],
      "metadata": {
        "id": "l1ZTNXWFSZvr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFV0emH1Sx_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hICLN37dS-tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tiCLYr1fS-qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 4\n",
        "\n",
        "The world bank has a Python wrapper for its api called `wbgapi`.  Examine the documentation [here](https://pypi.org/project/wbgapi/) and chose an endpoint(s) to query.  Find at least two endpoints of interest and create visualizations of this data.  Write a sentence or two about what you've found."
      ],
      "metadata": {
        "id": "odFitnLfS_wc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OlUX1Pg1TDwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMSHrxgbTDoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFLDHBnyTCmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 5\n",
        "\n",
        "\n",
        "Find an api of interest to you -- here is a list of some but feel free to google around [api list](https://github.com/public-apis/public-apis).  Ask a specific question that you want to use the data from the api to answer, make an appropriate request of the endpoints and do your best to provide an answer to your question asked.\n",
        "\n",
        "-------\n",
        "For example, maybe I'm interested in finding out recent artists similar to Rod Stewart.  I could use the LastFM api for this.  Perhaps you're interested in a lyrical analysis of Drake vs. Kendrick Lamar -- and want to compare the lexical diversity of different tracks; you can use the genius api for this.  Maybe I want to build an app to show a random cat picture with a dad joke.  The cat api and jokes api might work here."
      ],
      "metadata": {
        "id": "cWEmgwj4TEOq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLZySZcBTX2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0Jah7L5TYhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_PHOhDUTYd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 6\n",
        "\n",
        "Use the `praw` api [here](https://praw.readthedocs.io/en/stable/) to extract posts from two subreddits of interest to you.  Create a DataFrame based on the posts that contains columns that you feel are appropriate based on the structure of each post.  At a minimum you want a title of each post, the body, and the subreddit title:\n",
        "\n",
        "| Title | Text | Subreddit |\n",
        "| ------- | ------ | ------ |\n",
        "| If we could shrink ourselves down, <br/>at a certain size we would stop being <br/>able to hear anything because the sound <br/>waves would be too big for our tiny ear holes | None | showerthoughts |\n",
        "| How do I actually get good at Python? | I wouldnâ€™t call myself <br/>a complete new beginner in programming,<br/> I get the concepts. <br/>I know the basics ... <br/>how did you go from building simple scripts to building <br/>complex and big projects? | learnpython |"
      ],
      "metadata": {
        "id": "kG9bHcGXTZNT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCl97oVdTfiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pkeidLXETfep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 7\n",
        "\n",
        "Head over to [books to scrape](https://books.toscrape.com/).  Use `BeautifulSoup` to extract all the book titles and prices and assemble these in a DataFrame with two columns appropriately titled."
      ],
      "metadata": {
        "id": "iqfYtyhDba1B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZA14PHbTe3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0aVMtxkTadpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 8\n",
        "\n",
        "Head over to the [Countries of the World](https://www.scrapethissite.com/pages/simple/) site.  Use requests and BeautifulSoup to scrape all countries (250) data and assemble as a DataFrame with columns:\n",
        "\n",
        "| Country | Capital | Population | Area (km$^2$) | People/km$^2$ |\n",
        "| -----  | -------- | ---------  | ------------  | ------------  |\n",
        "| Andorra | Andorra la Vella | 84000 | 468.0 | 179.49 |"
      ],
      "metadata": {
        "id": "c0xyuyutbcRw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOxR9KbdadmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2TeY396XC9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}