{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josepeon/python_dad_class/blob/main/text_intro_to_rnn_dele.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification with Neural Networks"
      ],
      "metadata": {
        "id": "5SQWyog0AAOZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "e0uc39GMhd70"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "liI1vRV8hg2F"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifying Spam"
      ],
      "metadata": {
        "id": "uAI5zZVn8Cp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read in data\n",
        "spam = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/refs/heads/master/sms_spam.csv')"
      ],
      "metadata": {
        "id": "c7ifGrEZhkoD"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take a peek\n",
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X_Qo7jH1hmeZ",
        "outputId": "ba62b3da-aee5-4752-a50b-0d3551e809d2"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6046408-e290-476b-a816-9c7d1c71eede\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6046408-e290-476b-a816-9c7d1c71eede')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6046408-e290-476b-a816-9c7d1c71eede button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6046408-e290-476b-a816-9c7d1c71eede');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee68e143-1658-4a05-ac30-a0d298e1e93e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee68e143-1658-4a05-ac30-a0d298e1e93e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee68e143-1658-4a05-ac30-a0d298e1e93e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "spam",
              "summary": "{\n  \"name\": \"spam\",\n  \"rows\": 5574,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5160,\n        \"samples\": [\n          \"they released another Italian one today and it has a cosign option\",\n          \"I'm not. She lip synced with shangela.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a tokenizer\n",
        "tokenizer = Tokenizer(num_words = 500)"
      ],
      "metadata": {
        "id": "XOqnZA90i0vQ"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the tokenizer -- learns the vocabulary\n",
        "tokenizer.fit_on_texts(spam['text'].values)"
      ],
      "metadata": {
        "id": "XUWmDd-ik7MK"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at tokenizer\n",
        "tokenizer.num_words"
      ],
      "metadata": {
        "id": "30pDdCd1sfsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7634e1d3-bd39-4017-f360-50d7b6d25895"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create document term matrix (binarized)\n",
        "dtm = tokenizer.texts_to_matrix(spam['text'].values)"
      ],
      "metadata": {
        "id": "ZIs8UShtsfpg"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take a peek\n",
        "dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJc6IxLe8cea",
        "outputId": "0af091ce-b323-45f8-aebe-193f97b7ba78"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DQkwVMG4UilZ",
        "outputId": "0c3cca5e-0881-40f5-9b51-68a7130497ee"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam['text'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q_WhuHe2CTPz",
        "outputId": "39501e65-1560-4fc6-b461-eef10d572c1c"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[tokenizer.index_word[i] for i in range(1, 500)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BXZHi_Ptd657",
        "outputId": "8e2633a1-8392-4c37-8814-d8615f05145f"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'to',\n",
              " 'you',\n",
              " 'a',\n",
              " 'the',\n",
              " 'u',\n",
              " 'and',\n",
              " 'in',\n",
              " 'is',\n",
              " 'me',\n",
              " 'my',\n",
              " 'for',\n",
              " 'your',\n",
              " 'it',\n",
              " 'of',\n",
              " 'call',\n",
              " 'have',\n",
              " 'on',\n",
              " '2',\n",
              " 'that',\n",
              " 'now',\n",
              " 'are',\n",
              " 'so',\n",
              " 'but',\n",
              " 'not',\n",
              " 'or',\n",
              " 'do',\n",
              " 'can',\n",
              " 'at',\n",
              " \"i'm\",\n",
              " 'ur',\n",
              " 'get',\n",
              " 'will',\n",
              " 'if',\n",
              " 'be',\n",
              " 'with',\n",
              " 'just',\n",
              " 'no',\n",
              " 'we',\n",
              " 'this',\n",
              " '4',\n",
              " 'gt',\n",
              " 'lt',\n",
              " 'up',\n",
              " 'when',\n",
              " 'ok',\n",
              " 'free',\n",
              " 'from',\n",
              " 'go',\n",
              " 'how',\n",
              " 'all',\n",
              " 'out',\n",
              " 'what',\n",
              " 'know',\n",
              " 'like',\n",
              " 'good',\n",
              " 'then',\n",
              " 'got',\n",
              " 'come',\n",
              " 'was',\n",
              " 'its',\n",
              " 'am',\n",
              " 'time',\n",
              " 'only',\n",
              " 'day',\n",
              " 'love',\n",
              " 'there',\n",
              " 'send',\n",
              " 'he',\n",
              " 'want',\n",
              " 'text',\n",
              " 'as',\n",
              " 'txt',\n",
              " 'one',\n",
              " 'going',\n",
              " 'by',\n",
              " 'ü',\n",
              " \"i'll\",\n",
              " 'need',\n",
              " 'home',\n",
              " 'about',\n",
              " 'r',\n",
              " 'lor',\n",
              " 'sorry',\n",
              " 'stop',\n",
              " 'still',\n",
              " 'see',\n",
              " 'n',\n",
              " 'back',\n",
              " 'today',\n",
              " 'da',\n",
              " 'our',\n",
              " 'dont',\n",
              " 'reply',\n",
              " 'k',\n",
              " \"don't\",\n",
              " 'she',\n",
              " 'mobile',\n",
              " 'take',\n",
              " 'hi',\n",
              " 'tell',\n",
              " 'new',\n",
              " 'please',\n",
              " 'later',\n",
              " 'her',\n",
              " 'pls',\n",
              " 'any',\n",
              " 'think',\n",
              " 'been',\n",
              " 'they',\n",
              " 'phone',\n",
              " 'here',\n",
              " 'week',\n",
              " 'did',\n",
              " 'dear',\n",
              " 'some',\n",
              " 'well',\n",
              " 'has',\n",
              " '1',\n",
              " 'night',\n",
              " 'much',\n",
              " 'd',\n",
              " 'great',\n",
              " 'oh',\n",
              " 'who',\n",
              " 'hope',\n",
              " 'claim',\n",
              " 'an',\n",
              " 'hey',\n",
              " 'msg',\n",
              " 'where',\n",
              " 'him',\n",
              " 'more',\n",
              " 'too',\n",
              " 'happy',\n",
              " 'had',\n",
              " 'yes',\n",
              " 'give',\n",
              " 'c',\n",
              " 'make',\n",
              " 'way',\n",
              " 'work',\n",
              " \"it's\",\n",
              " 'www',\n",
              " 'wat',\n",
              " 'should',\n",
              " 'number',\n",
              " 'e',\n",
              " 'message',\n",
              " 'say',\n",
              " 'prize',\n",
              " 'tomorrow',\n",
              " 'right',\n",
              " 'already',\n",
              " 'after',\n",
              " 'ask',\n",
              " 'said',\n",
              " '3',\n",
              " 'cash',\n",
              " 'amp',\n",
              " 'doing',\n",
              " 'yeah',\n",
              " 'really',\n",
              " 'im',\n",
              " 'why',\n",
              " 'life',\n",
              " 'meet',\n",
              " 'them',\n",
              " 'find',\n",
              " 'miss',\n",
              " 'very',\n",
              " 'morning',\n",
              " 'babe',\n",
              " 't',\n",
              " 'last',\n",
              " 'win',\n",
              " 'thanks',\n",
              " 'would',\n",
              " 'cos',\n",
              " 'lol',\n",
              " 'anything',\n",
              " 'also',\n",
              " 'won',\n",
              " 'b',\n",
              " 'let',\n",
              " 'care',\n",
              " 'every',\n",
              " '150p',\n",
              " 'com',\n",
              " 'sure',\n",
              " 'pick',\n",
              " 'urgent',\n",
              " 'nokia',\n",
              " 'sent',\n",
              " 'keep',\n",
              " 'over',\n",
              " 'uk',\n",
              " 'something',\n",
              " 'contact',\n",
              " 'us',\n",
              " 'again',\n",
              " 'buy',\n",
              " 'min',\n",
              " 'gud',\n",
              " \"i've\",\n",
              " 'wait',\n",
              " 'cant',\n",
              " 'before',\n",
              " 'first',\n",
              " 'even',\n",
              " 'his',\n",
              " 's',\n",
              " '5',\n",
              " 'next',\n",
              " 'feel',\n",
              " 'were',\n",
              " \"can't\",\n",
              " 'nice',\n",
              " 'someone',\n",
              " 'went',\n",
              " 'thing',\n",
              " 'around',\n",
              " 'soon',\n",
              " \"that's\",\n",
              " 'which',\n",
              " 'off',\n",
              " 'tonight',\n",
              " 'could',\n",
              " 'place',\n",
              " 'money',\n",
              " 'service',\n",
              " 'tone',\n",
              " '50',\n",
              " 'late',\n",
              " 'many',\n",
              " 'per',\n",
              " 'customer',\n",
              " 'gonna',\n",
              " 'always',\n",
              " 'chat',\n",
              " 'ya',\n",
              " 'sleep',\n",
              " 'leave',\n",
              " 'co',\n",
              " 'down',\n",
              " 'x',\n",
              " 'sms',\n",
              " 'dun',\n",
              " 'friends',\n",
              " 'v',\n",
              " 'other',\n",
              " 'wan',\n",
              " '16',\n",
              " 'help',\n",
              " 'things',\n",
              " 'told',\n",
              " 'wish',\n",
              " 'hello',\n",
              " 'special',\n",
              " 'waiting',\n",
              " 'may',\n",
              " 'try',\n",
              " \"you're\",\n",
              " 'fine',\n",
              " '18',\n",
              " 'haha',\n",
              " 'coming',\n",
              " 'name',\n",
              " 'getting',\n",
              " 'done',\n",
              " 'year',\n",
              " 'same',\n",
              " 'guaranteed',\n",
              " 'yet',\n",
              " 'people',\n",
              " 'thk',\n",
              " 'use',\n",
              " 'friend',\n",
              " 'best',\n",
              " 'mins',\n",
              " 'heart',\n",
              " 'thought',\n",
              " '6',\n",
              " 'holiday',\n",
              " 'lunch',\n",
              " 'live',\n",
              " 'man',\n",
              " \"didn't\",\n",
              " 'talk',\n",
              " 'stuff',\n",
              " 'bit',\n",
              " 'class',\n",
              " 'y',\n",
              " 'smile',\n",
              " 'person',\n",
              " 'being',\n",
              " 'never',\n",
              " 'draw',\n",
              " 'few',\n",
              " 'cs',\n",
              " 'days',\n",
              " '7',\n",
              " 'yup',\n",
              " 'trying',\n",
              " 'meeting',\n",
              " 'thats',\n",
              " 'cool',\n",
              " 'job',\n",
              " 'better',\n",
              " 'house',\n",
              " 'ill',\n",
              " 'line',\n",
              " 'finish',\n",
              " 'long',\n",
              " 'ready',\n",
              " 'having',\n",
              " 'mind',\n",
              " 'car',\n",
              " 'end',\n",
              " 'wk',\n",
              " 'god',\n",
              " 'enjoy',\n",
              " '£1',\n",
              " 'latest',\n",
              " 'half',\n",
              " 'play',\n",
              " 'check',\n",
              " 'real',\n",
              " 'yo',\n",
              " 'lot',\n",
              " 'account',\n",
              " 'because',\n",
              " 'dat',\n",
              " 'than',\n",
              " 'chance',\n",
              " 'lar',\n",
              " 'receive',\n",
              " 'word',\n",
              " 'camera',\n",
              " 'eat',\n",
              " 'awarded',\n",
              " 'wanna',\n",
              " 'box',\n",
              " 'nothing',\n",
              " 'guess',\n",
              " 'sir',\n",
              " 'luv',\n",
              " 'start',\n",
              " 'problem',\n",
              " '1st',\n",
              " 'world',\n",
              " 'another',\n",
              " 'bt',\n",
              " 'liao',\n",
              " 'guys',\n",
              " 'big',\n",
              " 'dinner',\n",
              " 'month',\n",
              " 'sweet',\n",
              " 'ah',\n",
              " 'birthday',\n",
              " 'shows',\n",
              " 'into',\n",
              " 'shit',\n",
              " 'xxx',\n",
              " '£1000',\n",
              " 'po',\n",
              " 'girl',\n",
              " 'jus',\n",
              " 'might',\n",
              " 'ever',\n",
              " 'quite',\n",
              " 'cost',\n",
              " 'wont',\n",
              " 'watching',\n",
              " 'room',\n",
              " '150ppm',\n",
              " 'landline',\n",
              " 'offer',\n",
              " 'g',\n",
              " 'video',\n",
              " 'early',\n",
              " 'speak',\n",
              " 'once',\n",
              " 'aight',\n",
              " 'tv',\n",
              " 'called',\n",
              " 'watch',\n",
              " 'two',\n",
              " 'probably',\n",
              " 'rate',\n",
              " 'apply',\n",
              " '9',\n",
              " 'remember',\n",
              " 'pay',\n",
              " 'left',\n",
              " 'does',\n",
              " 'maybe',\n",
              " 'hear',\n",
              " 'pa',\n",
              " 'bed',\n",
              " 'forgot',\n",
              " 'll',\n",
              " 'boy',\n",
              " 'thanx',\n",
              " 'plan',\n",
              " 'shall',\n",
              " 'minutes',\n",
              " 'sat',\n",
              " 'actually',\n",
              " 'den',\n",
              " 'bad',\n",
              " 'princess',\n",
              " 'fun',\n",
              " 'code',\n",
              " 'ringtone',\n",
              " 'look',\n",
              " 'weekend',\n",
              " \"he's\",\n",
              " 'part',\n",
              " 'between',\n",
              " 'easy',\n",
              " 'reach',\n",
              " 'shopping',\n",
              " 'baby',\n",
              " 'made',\n",
              " 'dunno',\n",
              " 'orange',\n",
              " 'office',\n",
              " 'kiss',\n",
              " '2nd',\n",
              " 'dis',\n",
              " '10',\n",
              " 'anyway',\n",
              " 'little',\n",
              " 'leh',\n",
              " 'face',\n",
              " 'everything',\n",
              " 'didnt',\n",
              " 'hour',\n",
              " 'network',\n",
              " 'selected',\n",
              " 'enough',\n",
              " '000',\n",
              " 'thank',\n",
              " 'bus',\n",
              " \"how's\",\n",
              " 'looking',\n",
              " 'award',\n",
              " 'those',\n",
              " 'm',\n",
              " 'working',\n",
              " 'put',\n",
              " 'wife',\n",
              " 'town',\n",
              " \"there's\",\n",
              " 'most',\n",
              " 'afternoon',\n",
              " 'without',\n",
              " 'missing',\n",
              " 'tmr',\n",
              " 'evening',\n",
              " 'collect',\n",
              " 'asked',\n",
              " 'true',\n",
              " 'texts',\n",
              " '8',\n",
              " 'while',\n",
              " 'fuck',\n",
              " 'dad',\n",
              " 'until',\n",
              " 'wif',\n",
              " 'though',\n",
              " 'wanted',\n",
              " 'calls',\n",
              " 'since',\n",
              " 'pain',\n",
              " 'came',\n",
              " 'okay',\n",
              " 'says',\n",
              " 'must',\n",
              " 'school',\n",
              " 'join',\n",
              " 'mail',\n",
              " 'sexy',\n",
              " 'xmas',\n",
              " 'important',\n",
              " 'details',\n",
              " 'entry',\n",
              " 'goes',\n",
              " 'update',\n",
              " 'means',\n",
              " 'abt',\n",
              " 'able',\n",
              " 'hav',\n",
              " 'wake',\n",
              " 'tones',\n",
              " 'wot',\n",
              " 'bring']"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    super().__init__()\n",
        "    self.x = torch.tensor(X, dtype = torch.float)\n",
        "    self.y = torch.tensor(y, dtype = torch.float)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "ARFZcDfPCNnR"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dtm\n",
        "y = np.where(spam['type'] == 'ham', 0, 1)"
      ],
      "metadata": {
        "id": "iDtzLOGbDvwQ"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = torch.tensor(X, dtype = torch.float32)\n",
        "yt = torch.tensor(y, dtype = torch.float32)"
      ],
      "metadata": {
        "id": "teYl0qLYTG2M"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "BRGx5u69TGzM"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5l7e4c2WTGvj"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "sK-ekzymqkc3"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=.2)"
      ],
      "metadata": {
        "id": "aszcYuSVqkVo"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzIechzNqkR1",
        "outputId": "c75117fe-16ce-4471-e573-e41f0af224b5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 1.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3kirParqkNg"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create data class\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TextDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "T5qkcKgO8et8",
        "outputId": "da747862-dfdf-4152-924d-0ddbfc7ec5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3856549849.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(X, dtype = torch.float)\n",
            "/tmp/ipython-input-3856549849.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y, dtype = torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset and loader -- making batches of our bigger dataset\n",
        "trainloader = DataLoader(train_dataset, batch_size = 32)\n",
        "#dataset and loader\n",
        "testloader = DataLoader(test_dataset, batch_size = 32)"
      ],
      "metadata": {
        "id": "MYZ6Jbws8eqS"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(in_features=500, out_features=1000),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(1000, 100),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(100, 1),\n",
        "                      nn.Sigmoid()\n",
        "                      )"
      ],
      "metadata": {
        "id": "XCsBGMfMUJvR"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(Xt)"
      ],
      "metadata": {
        "id": "FdYALX4qUJrY",
        "outputId": "d5af20f3-a077-4b51-e4f2-987efac86c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5250],\n",
              "        [0.5198],\n",
              "        [0.5215],\n",
              "        ...,\n",
              "        [0.5230],\n",
              "        [0.5183],\n",
              "        [0.5227]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "6IzlOCZqUJnu"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "w3LFxY8NYQTB"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keep track of the losses\n",
        "losses = []\n",
        "#train it for 20 epochs\n",
        "for epoch in tqdm(range(20)):\n",
        "  #iterate over the batches\n",
        "  for x, y in trainloader:\n",
        "    #feeds data into the model\n",
        "    yhat = model(x)\n",
        "    #evaluate the predictions\n",
        "    loss =loss_fn(yhat, y.unsqueeze(1))\n",
        "    #update the weights/params\n",
        "    optimizer.zero_grad() #pytorch house cleaning\n",
        "    loss.backward() #pass info backward\n",
        "    optimizer.step() #step toward less loss\n",
        "    losses.append(loss.item()) #tracking the loss"
      ],
      "metadata": {
        "id": "8tsmg2dpUJkN",
        "outputId": "8d126ebd-b9c9-44d2-96f6-2ae18eaba8fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:38<00:00,  1.94s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = model(X_train)\n",
        "ytrain_preds = torch.where(train_predictions> .5, 1, 0)"
      ],
      "metadata": {
        "id": "sWFTUrziUJbP"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(ytrain_preds.squeeze(1) == y_train)/len(y_train)"
      ],
      "metadata": {
        "id": "SGVgP42ZZ9mX",
        "outputId": "41c6a0ca-b974-4a65-9999-0215ee3437f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9998)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest_preds = torch.where(model(X_test) > .5, 1, 0)\n",
        "torch.sum(ytest_preds.squeeze(1) == y_test)/len(y_test)"
      ],
      "metadata": {
        "id": "oHWJGU-Qa0y6",
        "outputId": "6c77d58d-a9ab-400f-da91-9671dee9c3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9874)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss and optimizer\n",
        "class TextModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lin1 = nn.Linear(in_features = 500, out_features = 100)\n",
        "    self.lin2 = nn.Linear(100, 100)\n",
        "    self.lin3 = nn.Linear(100, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.act(self.lin1(x))\n",
        "    x = self.act(self.lin2(x))\n",
        "    return self.sigmoid(self.lin3(x))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bpsixqUc8emJ"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training function\n",
        "model = TextModel()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4h0spe_p8eie"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model, 'textmodel.pt')"
      ],
      "metadata": {
        "id": "RujMKJoPbwBO"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "saG8QSjKfiVt"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "for epoch in tqdm(range(100)):\n",
        "  losses = 0\n",
        "  for x,y in trainloader:\n",
        "    yhat = model(x)\n",
        "    y = y.reshape(-1, 1)\n",
        "    loss = loss_fn(yhat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses += loss.item()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch {epoch} Loss: {losses}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXpxaYe88ece",
        "outputId": "4c3b8e3f-13d6-4d67-a965-04f7d7912b62"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:00<01:26,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 19.897117960848846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [00:08<01:08,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 0.3340495549133209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 21/100 [00:17<01:04,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Loss: 0.20322521342030697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [00:27<01:05,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Loss: 0.19342272566609675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 41/100 [00:32<00:34,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Loss: 0.20008202656111607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 51/100 [00:39<00:39,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Loss: 4.507611352721057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 61/100 [00:43<00:17,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Loss: 0.153403052560737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 71/100 [00:50<00:18,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Loss: 0.1568060389889246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 81/100 [00:56<00:12,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Loss: 0.16012698261154504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 91/100 [01:01<00:05,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Loss: 0.15900360136278344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = torch.tensor(X_test, dtype = torch.float)"
      ],
      "metadata": {
        "id": "_DcEHs4y8eZn",
        "outputId": "ab6b486d-f76b-476d-f6fd-199afd6cf735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-747476605.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Xt = torch.tensor(X_test, dtype = torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output = model(Xt) #model predictions"
      ],
      "metadata": {
        "id": "aEy8zfP0HNr5"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GVJHCGeqEJM",
        "outputId": "cc1ca421-f960-4249-a779-07f5eaddb446"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.9505e-20],\n",
              "        [1.0000e+00],\n",
              "        [6.8780e-36],\n",
              "        ...,\n",
              "        [0.0000e+00],\n",
              "        [0.0000e+00],\n",
              "        [1.3955e-08]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting probabilities to prediction\n",
        "preds = np.where(np.array(output.detach()) >= .5, 1, 0)"
      ],
      "metadata": {
        "id": "DkVQymo1HUui"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhEbGWR8HUnh",
        "outputId": "475da76a-d940-4600-d1c9-94a122a150f9"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.where(spam['type'] == 'ham', 0, 1)"
      ],
      "metadata": {
        "id": "UONO0UuHHUi1"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(preds[:, 0] == y_test)/len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppU6XUcLHrgv",
        "outputId": "40be0f2f-8373-42b4-c619-1dbf48fbd44c"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9848)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1 - sum(y_test)/len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFvjLUjJgGJu",
        "outputId": "8bb2d246-159c-4c8c-dc36-cea335426ddd"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8538)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic RNN\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/440px-Recurrent_neural_network_unfold.svg.png)"
      ],
      "metadata": {
        "id": "zajZdySD9Lxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create sequences\n",
        "sequences = tokenizer.texts_to_sequences(spam['text'].values)"
      ],
      "metadata": {
        "id": "14ohZWmqlBXn"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at first sequence\n",
        "sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iAvE73XlGNf",
        "outputId": "183c3dce-fd93-4b49-8719-c98753332efb"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49, 471, 64, 8, 88, 123, 351, 148, 67, 58, 145]"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_qBoi0aWhDi",
        "outputId": "33d9de03-2add-4a2a-ca77-c4457c664108",
        "collapsed": true
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compare to text\n",
        "spam['text'].values[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WBoD5QfPlK7X",
        "outputId": "b3f79568-fcff-4ad7-f8c4-3ec5539d7937"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ok lar... Joking wif u oni...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pad and make all same length\n",
        "sequences = pad_sequences(sequences, maxlen=100)"
      ],
      "metadata": {
        "id": "PmeaiuOAlNGD"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#examine results\n",
        "sequences[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH6zRxhxmlrt",
        "outputId": "0d5290a4-38d9-4ba7-8739-d36d5807a5a6"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYw2vJpntRVx",
        "outputId": "8e542042-44f1-40be-d0a3-09607ba50071"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  46, 336, 472,   6], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQzbGDJDjBQ6"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example rnn\n",
        "rnn = nn.RNN(input_size = 100,\n",
        "             hidden_size = 30,\n",
        "             num_layers = 1,\n",
        "             batch_first = True)"
      ],
      "metadata": {
        "id": "7GnZn1epsSEi"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pass data through\n",
        "sample_sequence = torch.tensor(sequences[1],\n",
        "                               dtype = torch.float,\n",
        "                               ).reshape(1, -1)\n",
        "sample_sequence.shape"
      ],
      "metadata": {
        "id": "Fr2mNE_0swQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e80b576-97da-4b31-b5bd-df5830fd5bb2"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#output\n",
        "output, hidden = rnn(sample_sequence)"
      ],
      "metadata": {
        "id": "97X1o7qHmw5n"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden\n",
        "hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONbv5VGa2EhR",
        "outputId": "befda5e8-a899-4ec4-d344-0a6f28941ced"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#linear layer\n",
        "output.shape"
      ],
      "metadata": {
        "id": "EyjoR6x1tIRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89df701c-acaf-45e6-c42d-d3adcc5230fd"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pass through linear\n",
        "lin1 = nn.Linear(in_features = 30, out_features = 1)"
      ],
      "metadata": {
        "id": "wy86PysZh4yt"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin1(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-24s8_ZMNQs",
        "outputId": "7573fe8c-f440-43a8-d035-c0069ff424e5"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7749]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in trainloader:\n",
        "  print(x.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsLIq2RpMoe5",
        "outputId": "7a1c2391-e5b2-4e7b-cf5f-80a61a1f6cc6"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sequences, yt)"
      ],
      "metadata": {
        "id": "_rju-r76iLZH"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype = torch.float32), y_train)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype = torch.float32), y_test)"
      ],
      "metadata": {
        "id": "k3Rr0n-kiLS0"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trailoader = DataLoader(train_dataset, batch_size = 32)\n",
        "testloader = DataLoader(test_dataset, batch_size = 32)"
      ],
      "metadata": {
        "id": "OBQILVUciLGP"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.RNN(input_size = 100, hidden_size  =50, num_layers=2),\n",
        "                      nn.Linear(in_features = 50, out_features=1),\n",
        "                      nn.Sigmoid())"
      ],
      "metadata": {
        "id": "WsOmXTfqjcoW"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_rnn = nn.RNN(input_size = 100, hidden_size  =50, num_layers=2)\n",
        "ex_rnn(train_dataset[0][0].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzzFlnYtkGnN",
        "outputId": "a6e2c24a-5354-49b6-96fa-ae1599dda060"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.4118, -0.0025, -0.4569,  0.5110,  0.0858,  0.2192, -0.2276, -0.0446,\n",
              "          -0.8004, -0.0141,  0.1393, -0.1261, -0.4060, -0.0451, -0.6247,  0.2486,\n",
              "           0.3606,  0.3140,  0.0907, -0.3226,  0.0997, -0.1068,  0.1623, -0.5177,\n",
              "           0.4297,  0.3292,  0.0213, -0.1083, -0.3810,  0.2312, -0.4693,  0.3344,\n",
              "           0.4966,  0.7659,  0.2372, -0.0045, -0.2174,  0.7303,  0.5353,  0.2707,\n",
              "          -0.6379,  0.0521, -0.1645,  0.3039, -0.0313,  0.3005, -0.0924, -0.4060,\n",
              "          -0.2611,  0.1055]], grad_fn=<SqueezeBackward1>),\n",
              " tensor([[-1.0000, -0.9699, -0.8960,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -0.9999,  1.0000,\n",
              "           1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  0.9991,\n",
              "           1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -0.7305, -1.0000,\n",
              "           1.0000, -0.5038, -0.9836,  1.0000, -1.0000, -1.0000, -1.0000, -0.8787,\n",
              "           1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
              "           1.0000, -1.0000],\n",
              "         [-0.4118, -0.0025, -0.4569,  0.5110,  0.0858,  0.2192, -0.2276, -0.0446,\n",
              "          -0.8004, -0.0141,  0.1393, -0.1261, -0.4060, -0.0451, -0.6247,  0.2486,\n",
              "           0.3606,  0.3140,  0.0907, -0.3226,  0.0997, -0.1068,  0.1623, -0.5177,\n",
              "           0.4297,  0.3292,  0.0213, -0.1083, -0.3810,  0.2312, -0.4693,  0.3344,\n",
              "           0.4966,  0.7659,  0.2372, -0.0045, -0.2174,  0.7303,  0.5353,  0.2707,\n",
              "          -0.6379,  0.0521, -0.1645,  0.3039, -0.0313,  0.3005, -0.0924, -0.4060,\n",
              "          -0.2611,  0.1055]], grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(train_dataset[0][0].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "XzPBnwOoj8WX",
        "outputId": "2c13aec2-bba9-4ea9-fe7e-e138396df340"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-219371049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    super().__init__()\n",
        "    self.x = torch.tensor(X, dtype = torch.float)\n",
        "    self.y = torch.tensor(y, dtype = torch.float)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "Kss5sft0OosZ"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class\n",
        "class BasicRNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.rnn = nn.RNN(input_size = 100,\n",
        "                    hidden_size = 50,\n",
        "                    num_layers = 3,\n",
        "                    batch_first = True)\n",
        "    self.lin1 = nn.Linear(in_features = 50, out_features=1000)\n",
        "    self.lin2 = nn.Linear(1000, 100)\n",
        "    self.lin3 = nn.Linear(100, 1)\n",
        "    self.act = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, _ = self.rnn(x) #extracting important information\n",
        "    x = self.act(self.lin1(x)) #multilayer perceptron -- to predict\n",
        "    x = self.act(self.lin2(x))\n",
        "    x = self.sigmoid(self.lin3(x))\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "x0N9mpg9h5og"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "X = sequences\n",
        "y = np.where(spam['type'] == 'spam', 1, 0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
        "traindata = TextDataset(X_train, y_train)\n",
        "trainloader = DataLoader(traindata, batch_size = 32)"
      ],
      "metadata": {
        "id": "stjsLaxj5k40"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer and loss\n",
        "model = BasicRNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4ACZI673-RpV"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "for epoch in tqdm(range(100)):\n",
        "  losses = 0\n",
        "  for x,y in trainloader:\n",
        "    yhat = model(x)\n",
        "    y = y.reshape(-1, 1)\n",
        "    loss = loss_fn(yhat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses += loss.item()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch {epoch} Loss: {losses}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLj-NUK5-TeE",
        "outputId": "ee4b8833-a880-4750-9e69-39332262654b"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:02<03:18,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 52.82915246486664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [00:24<03:31,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 54.446724608540535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 21/100 [00:49<03:16,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Loss: 54.449391439557076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [01:13<02:52,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Loss: 54.45001582801342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 41/100 [01:38<02:27,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Loss: 54.450166910886765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 51/100 [02:02<02:04,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Loss: 54.45020292699337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 61/100 [02:27<01:37,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Loss: 54.45021215081215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 71/100 [02:51<01:13,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Loss: 54.450213357806206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 81/100 [03:16<00:48,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Loss: 54.4502155482769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 91/100 [03:41<00:22,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Loss: 54.45021505653858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [04:03<00:00,  2.44s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = torch.tensor(X_test, dtype = torch.float)"
      ],
      "metadata": {
        "id": "M_uQWrJaPRwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(Xt)"
      ],
      "metadata": {
        "id": "T5XcG1OpPZ2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.where(np.array(output.detach()) >= .5, 1, 0)"
      ],
      "metadata": {
        "id": "hwS2m5rcPZ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preds = output.argmax(axis = 1)"
      ],
      "metadata": {
        "id": "eZgcoSgzM3Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "izZ6GyxHwV2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y = np.where(spam['type'] == 'ham', 0, 1)"
      ],
      "metadata": {
        "id": "J8BeML_qPZ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y.shape"
      ],
      "metadata": {
        "id": "YtBc83hINEL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(preds.reshape(1115,) == y_test)/len(y_test)"
      ],
      "metadata": {
        "id": "GEhgDz-9wiP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "zGZZTw9s-VxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.LSTM()\n",
        "class BasicLSTM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.rnn = nn.LSTM(input_size = 100,\n",
        "                    hidden_size = 100,\n",
        "                    num_layers = 1,\n",
        "                    batch_first = True)\n",
        "\n",
        "    self.lin1 = nn.Linear(in_features = 100, out_features=100)\n",
        "    self.lin2 = nn.Linear(in_features = 100, out_features = 1)\n",
        "    self.act = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, _ = self.rnn(x)\n",
        "    x = self.act(self.lin1(x))\n",
        "    x = self.lin2(x)\n",
        "    return self.sigmoid(x)"
      ],
      "metadata": {
        "id": "o6sdapW1-XpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicLSTM()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "iRFR5kjC-Xlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "for epoch in range(10):\n",
        "  losses = 0\n",
        "  for x,y in trainloader:\n",
        "    yhat = model(x)\n",
        "    y = y.reshape(-1, 1)\n",
        "    loss = loss_fn(yhat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses += loss.item()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch {epoch} Loss: {losses}')"
      ],
      "metadata": {
        "id": "5ltm2mqT-Xh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = torch.tensor(X_test, dtype = torch.float)\n",
        "output = model(Xt)\n",
        "preds = np.where(np.array(output.detach()) >= .5, 1, 0)\n",
        "sum(preds[:, 0] == y_test)/len(y_test)"
      ],
      "metadata": {
        "id": "-BAJowK6-Xee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pad and make all same length\n",
        "sequences = pad_sequences(sequences, maxlen=30)"
      ],
      "metadata": {
        "id": "k63sNp5Q-Xa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "id": "FEAht9gg-XWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sequences\n",
        "y = np.where(spam['type'] == 'spam', 1, 0)\n",
        "data = TextDataset(X, y)\n",
        "loader = DataLoader(data, batch_size = 32)"
      ],
      "metadata": {
        "id": "RPTeRZtq-UM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.rnn = nn.GRU(input_size = 30,\n",
        "                    hidden_size = 30,\n",
        "                    num_layers = 2,\n",
        "                    batch_first = True)\n",
        "\n",
        "    self.lin1 = nn.Linear(in_features = 30, out_features=100)\n",
        "    self.lin2 = nn.Linear(in_features = 100, out_features = 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, _ = self.rnn(x)\n",
        "    x = self.lin1(x)\n",
        "    x = self.lin2(x)\n",
        "    return self.sigmoid(x)"
      ],
      "metadata": {
        "id": "6naIG8zXcMHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN2()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4rvMTz63cd56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "for epoch in range(100):\n",
        "  losses = 0\n",
        "  for x,y in loader:\n",
        "    yhat = model(x)\n",
        "    y = y.reshape(-1, 1)\n",
        "    loss = loss_fn(yhat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses += loss.item()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch {epoch} Loss: {losses}')"
      ],
      "metadata": {
        "id": "Usld0UXHcpWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = torch.tensor(sequences, dtype = torch.float)\n",
        "output = model(Xt)\n",
        "preds = np.where(np.array(output.detach()) >= .5, 1, 0)\n",
        "y = np.where(spam['type'] == 'ham', 0, 1)\n",
        "sum(preds[:, 0] == y)/len(y)"
      ],
      "metadata": {
        "id": "7oxNBjhtcsoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwk3h3ptmaM8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}